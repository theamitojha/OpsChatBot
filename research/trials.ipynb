{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Graph' from 'langchain' (c:\\Users\\Dell\\anaconda3\\envs\\opschatbot\\lib\\site-packages\\langchain\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, OpenAI, PromptTemplate\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph, Node, Tool\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StdOutCallbackHandler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melasticsearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Elasticsearch\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Graph' from 'langchain' (c:\\Users\\Dell\\anaconda3\\envs\\opschatbot\\lib\\site-packages\\langchain\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# data_management_system_tool.py\n",
    "import os\n",
    "import json\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.agents import Tool\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_management_system(query_params: dict) -> str:\n",
    "    # Initialize SparkSession\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"DataManagementSystem\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Connect to Elasticsearch\n",
    "    es_hosts = [\"http://localhost:9200\"]\n",
    "    es = Elasticsearch(es_hosts)\n",
    "\n",
    "    try:\n",
    "        # Construct Elasticsearch query based on query_params\n",
    "        s = Search(using=es, index='logs')\n",
    "        if 'order_id' in query_params:\n",
    "            s = s.filter('term', order_id=query_params['order_id'])\n",
    "        if 'timestamp' in query_params:\n",
    "            s = s.filter('range', timestamp={'lte': query_params['timestamp']})\n",
    "        # Add other filters as needed\n",
    "\n",
    "        # Execute query and get results\n",
    "        response = s.execute()\n",
    "        logs = [hit.to_dict() for hit in response]\n",
    "\n",
    "        # Create DataFrame from logs\n",
    "        df = spark.createDataFrame(logs)\n",
    "\n",
    "        # Data Processing using Spark\n",
    "        # Filtering and Transformation\n",
    "        df_filtered = df.filter(col('status').isNotNull())\n",
    "        df_transformed = df_filtered.select('appName', 'status', 'timestamp', 'errorDetails')\n",
    "\n",
    "        # Correlation (Example: Order by timestamp)\n",
    "        df_correlated = df_transformed.orderBy('timestamp')\n",
    "\n",
    "        # Collect results\n",
    "        processed_logs = df_correlated.collect()\n",
    "\n",
    "        # Convert processed logs to string\n",
    "        processed_logs_str = '\\n'.join([str(row.asDict()) for row in processed_logs])\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        return processed_logs_str if processed_logs_str else 'No relevant logs found.'\n",
    "    except Exception as e:\n",
    "        spark.stop()\n",
    "        return f'Error in Data Management System Tool: {str(e)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInterpretQueryNode\u001b[39;00m(\u001b[43mNode\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Use LLM to interpret the query and extract parameters\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract the intent and parameters from the following query:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProvide the result in JSON format with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Node' is not defined"
     ]
    }
   ],
   "source": [
    "class InterpretQueryNode(Node):\n",
    "    def run(self, query: str) -> dict:\n",
    "        # Use LLM to interpret the query and extract parameters\n",
    "        prompt = f\"Extract the intent and parameters from the following query:\\n\\n{query}\\n\\nProvide the result in JSON format with 'intent' and 'parameters'.\"\n",
    "        interpretation = llm(prompt)\n",
    "        # Parse the interpretation to get intent and parameters\n",
    "        try:\n",
    "            interpretation_json = json.loads(interpretation)\n",
    "            return {\n",
    "                \"intent\": interpretation_json.get(\"intent\"),\n",
    "                \"parameters\": interpretation_json.get(\"parameters\")\n",
    "            }\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"intent\": None,\n",
    "                \"parameters\": {}\n",
    "            }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opschatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
